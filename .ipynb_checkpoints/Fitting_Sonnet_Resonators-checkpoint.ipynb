{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script is capable to work with files that contain simulation data of particular layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import sys\n",
    "sys.path.append( \"D:/shamil_docs/jupyter_dir/lib\" ) # include path with resonator_tools module\n",
    "from resonator_tools.circuit import notch_port\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "\n",
    "# abs path to dir that contain csv files with data to plot\n",
    "dir_name = \"D:/shamil_docs/Qubit projects/Transmission_line_with_flux_qbits_in_resonators/Resonator_Qfactor_sonnet_6GHz_to_9GHz/csv_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important notes\n",
    "\".csv\" files may contain data exported from sonnet with the following way:\n",
    "\"sonnet response viewer -> output-> S,Z,Y parameters -> (format list) = spreadsheet\"\n",
    "and the second format parameter should be set to \"Mag-Angle\"\n",
    "\n",
    "every file may contain multiple sweeps \n",
    "(in case you made parameter or any other multiple data \n",
    "sweep and want to save all of the results in single file)\n",
    "any such files should be marked with keyword \"_multi\" in the end of it's name\n",
    "\n",
    "if file contains single sweep (in case it is to hard to parametrize sophisticated design)\n",
    "parameters should be stored in it's name in the following format:\n",
    "\"Transmission_line_with_resonator_6GHz_toLine_40_Lcoupling_100_Z0b_20\"\n",
    "(all parameter names and their values must be separated by underscore)\n",
    "\n",
    "\"### CUSTOMIZATION SECTION ... ###\" sections reflect that they are unique for specified design or parameter combinations and should be modified by user manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single file fitting and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"1_Transmission_line_with_resonator_6GHz_Lcoupling_400_toLine_35\"\n",
    "with open(dir_name + file_name + \".csv\") as f:\n",
    "    data = list(csv.reader(f, delimiter=\" \"))\n",
    "[data.pop(0) for i in range(8)] # get rid of context strings in file header\n",
    "freq = np.zeros( len(data), dtype=np.float64 )\n",
    "s21_amp = np.zeros( len(data), dtype=np.float64 )\n",
    "s21_phase = np.zeros( len(data), dtype=np.float64 )\n",
    "for i,row in enumerate(data):\n",
    "    freq[i] = row[0]\n",
    "    s21_amp[i] = row[3]\n",
    "    s21_phase[i] = row[4]\n",
    "s21_phase *= np.pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(5,7), sharex=True)\n",
    "axes[0].plot(freq,s21_amp)\n",
    "axes[1].plot(freq,s21_phase)\n",
    "axes[0].set_ylabel(\"$|S_{21}^2|$ [dB]\")\n",
    "axes[1].set_ylabel(r\"$\\angle S_{21}$ [rad]\")\n",
    "axes[1].set_xlabel(\"Frequency [GHz]\")\n",
    "plt.savefig(\"sim_res_S21.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "port1 = notch_port( freq, s21_amp*np.exp( 1j*s21_phase ) )\n",
    "port1.autofit()\n",
    "port1.fitresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "port1.plotall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting all files and storing them into \"Results.csv\" that is compatible with Excel 2010 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_number( val ):\n",
    "    try:\n",
    "        float( val )\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def add_default( params_in_file, param_defaults ):\n",
    "    for key,val in params_in_file.items(): \n",
    "        if( val == None ):\n",
    "            params_in_file[key] = param_defaults[key]\n",
    "            \n",
    "def load_csv_from_dir( dir_name, param_names, param_defaults ):\n",
    "    '''\n",
    "    @description: \n",
    "    function loads \".csv\" files from directory specified by 'dir_name'\n",
    "    all this files should be generated by Sonnet Response viewer\n",
    "    as a spreadsheets with format Mag-Angle\n",
    "    function also maps data to parameter grid\n",
    "    parameters names must be supplied through @param_names as list of strings\n",
    "    parameters name must coicide with parameters in file names and with\n",
    "    parameters defined inside Sonnet UI\n",
    "    \n",
    "    if file has multiple sweeps its name must end with \"_multi.csv\"\n",
    "    this reflects that parameter combinations, defined inside the\n",
    "    Sonnet UI, are stored inside the file\n",
    "    example: \"Transmission_line_with_resonator_6GHz_toLine_40_Lcoupling_100_to_400_Z0b_30_multi\"\n",
    "    in case there are some parameters that you are going to include into \n",
    "    parameter grid but they are not written by Sonnet in file content\n",
    "    you may define their values in the file name,\n",
    "    in format that corresponds for files containing sigle sweep\n",
    "    \n",
    "    if file contains single sweep it name must contain all of the parameters\n",
    "    in the following format:\n",
    "    \"Transmission_line_with_resonator_6GHz_toLine_25_Lcoupling_100_Z0b_30\"\n",
    "    this name is interpreted as follows:\n",
    "    toLine = 25\n",
    "    Lcoupling = 100\n",
    "    Z0b = 30\n",
    "    every parameter name must be followed by its value and every word\n",
    "    is separated by uderscore\n",
    "    \n",
    "    @note: currently this function extracts only columns 4 and 5\n",
    "            that corresponds to S21 parameters 05.08.2017\n",
    "    \n",
    "    \n",
    "    parameters\n",
    "    @dir_name: absolute path to directory with files\n",
    "    @param_names: names of the parameters that will form parameter grid\n",
    "                [\"Lcoupling\",\"toLine\",\"Z0b\"] \n",
    "    @param_defaults: dictionary with parameter names and their default values\n",
    "                    this values will be used in case function can't determine \n",
    "                    some parameter value from file name or its content\n",
    "                    {\"Lcoupling\":300,\"toLine\":50,\"Z0b\":30}\n",
    "                    \n",
    "    return: file_names, params, freqs, s21_data\n",
    "    @file_names: file names that reflects origins of every\n",
    "                s21_data element correspondingly \n",
    "                (file_names may have duplicates, since )\n",
    "    @params: parameter name as list of strings\n",
    "    @freqs: list of 1D numpy.arrays with dtype=np.float64 \n",
    "            that stores frequency points that correspond to s21_data content\n",
    "    @s21_data: list of 1D numpy.arrays with dtype=np.complex\n",
    "                that stores actual s21_data points as complex numbers\n",
    "    '''\n",
    "    #\"param_grid\" stores all possible values of each parameter\n",
    "    # [[p11,p12,p13,...],...,[pn1,pn2,...]] - first index is the parameter number\n",
    "    param_grid = [[] for name in param_names] \n",
    "    # due to this approach every simulation data set should be assigned with coordinates\n",
    "    # in this \"parameter grid space\" \n",
    "    #(coordinates are list of integers referring to point in param_grid)\n",
    "\n",
    "    ### CUSTOMIZATION SECTION START ###\n",
    "    # prepare calculated data attributes\n",
    "    fit_results = [] # Qc - quality factor of every resonanse in scheme\n",
    "    ### CUSTOMIZATION SECTION END ###\n",
    "\n",
    "\n",
    "    # getting names of all files in the specified direcory \"dir_name\"\n",
    "    file_names = [f for f in listdir(dir_name) if isfile(join(dir_name,f))]\n",
    "\n",
    "    # filter only \"csv\" files\n",
    "    file_lines = [f.split('_') for f in file_names]\n",
    "    files = [f for i,f in enumerate(file_names) if file_lines[i][-1].split('.')[-1] == \"csv\"]\n",
    "\n",
    "    freqs = []\n",
    "    s_data = []\n",
    "    params = []\n",
    "    files_ret = []\n",
    "    \n",
    "    # exctracting parameter's grid from name of files or their content\n",
    "    # mapping exctracted s_data to the grid\n",
    "    # iterating over all \"csv\" files:\n",
    "    for f_index,f in enumerate(file_lines):\n",
    "        # handling files with particular parameters stored in their name\n",
    "        if( f[-1].split('.')[0] != \"multi\" ): # in case if file store params in it's name\n",
    "            params_in_file = {name:None for name in param_names}\n",
    "            for param in param_names:\n",
    "                params_in_file[param] = f[f.index(param) + 1].split('.')[0]\n",
    "                # split('.') - in case of file name end with number e.g. \"...30.csv\"\n",
    "\n",
    "                # adding default parameters \n",
    "                # if they were ommited in particular parameter group\n",
    "                add_default( params_in_file, param_defaults )\n",
    "\n",
    "            # setting parameters corresponding to the freqs and s_data\n",
    "            # that are added in the code below\n",
    "            params.append( [params_in_file[name] for name in param_names] )\n",
    "            files_ret.append(file_names[f_index])\n",
    "            with open( dir_name + files[f_index] ) as csv_file:\n",
    "                # load the whole file\n",
    "                file_rows = list( csv.reader(csv_file, delimiter=\" \") )\n",
    "\n",
    "                [file_rows.pop(0) for i in range(8)] # get rid of context strings in file header\n",
    "                freq = np.zeros( len(file_rows), dtype=np.float64 )\n",
    "                s21_amp = np.zeros( len(file_rows), dtype=np.float64 )\n",
    "                s21_phase = np.zeros( len(file_rows), dtype=np.float64 )\n",
    "                for i,row in enumerate(file_rows):\n",
    "                    freq[i] = row[0]\n",
    "                    s21_amp[i] = row[3]\n",
    "                    s21_phase[i] = row[4]\n",
    "                s21_phase *= np.pi/180\n",
    "                freqs.append(freq)\n",
    "                s_data.append( s21_amp*np.exp( 1j*s21_phase ) )\n",
    "\n",
    "\n",
    "        else: # in case of multiparameter file\n",
    "            # reading s21 parameters from file\n",
    "            with open( dir_name + files[f_index] ) as csv_file:\n",
    "\n",
    "                # getting local default parameters from file name\n",
    "                param_local_defaults = {name:None for name in param_names}\n",
    "                for param in param_names:\n",
    "                    try:\n",
    "                        param_local_defaults[param] = f[f.index(param) + 1].split('.')[0]\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                    # split('.') - in case of file name end with number e.g. \"...30.csv\"\n",
    "\n",
    "                # adding default parameters from global to local \n",
    "                # in case some of the parameters still omitted even in file name\n",
    "                add_default( param_local_defaults, param_defaults )\n",
    "\n",
    "                # load the whole file\n",
    "                file_rows = list( csv.reader(csv_file, delimiter=\" \") )\n",
    "\n",
    "                params_in_file = {name:None for name in param_names}\n",
    "                current_row_i = 0\n",
    "                while( current_row_i != len(file_rows) ): # if end of file is not reached\n",
    "                    # scanning rows for parameter definition grop\n",
    "                    group_found = False\n",
    "                    while(True):\n",
    "                        row = file_rows[current_row_i]\n",
    "                        \n",
    "                        # finding group of rows with specified parameters\n",
    "                        if( row[1] is \"=\" ):\n",
    "                            print( current_row_i )\n",
    "                            group_found = True\n",
    "                            # adding defined parameter\n",
    "                            params_in_file[row[0]] = row[2]\n",
    "                            current_row_i += 1\n",
    "                            continue # move to the next row\n",
    "\n",
    "\n",
    "                        # if all parameters is recorded and the first element is number\n",
    "                        # add values to ommited parameters and read s_data and freq\n",
    "                        if( (group_found is True) and is_number(row[0]) ):\n",
    "                            # adding local default parameters \n",
    "                            # if they were ommited in particular parameter group\n",
    "                            add_default( params_in_file, param_local_defaults )\n",
    "                            # setting parameters corresponding to the freqs and s_data\n",
    "                            # that are added in the code below\n",
    "                            params.append( [params_in_file[name] for name in param_names] ) \n",
    "                            files_ret.append(file_names[f_index])\n",
    "                            break # goto adding of s_data and freq\n",
    "                        else: # move to the next row\n",
    "                            current_row_i += 1\n",
    "\n",
    "                    ## adding s-data that follows the parameter group ##\n",
    "                    # counting length of freq and s_data\n",
    "                    num_rows = 0\n",
    "                    while( (current_row_i + num_rows) < len(file_rows) and \n",
    "                          is_number(file_rows[current_row_i + num_rows][0]) ): \n",
    "                          num_rows += 1 \n",
    "\n",
    "                    # collecting data\n",
    "                    this_freqs = np.zeros( num_rows, dtype=np.float64 )\n",
    "                    this_s21_amp = np.zeros( num_rows, dtype=np.float64 )\n",
    "                    this_s21_phase = np.zeros( num_rows, dtype=np.float64 )\n",
    "\n",
    "                    # scanning through the data and collecting values\n",
    "                    for offset in range(num_rows):\n",
    "                        current_row = file_rows[current_row_i + offset]\n",
    "                        this_freqs[offset] = current_row[0]\n",
    "                        this_s21_amp[offset] = current_row[3]\n",
    "                        this_s21_phase[offset] = current_row[4]\n",
    "\n",
    "                    # storing values into s_data and freq\n",
    "                    freqs.append( this_freqs )\n",
    "                    this_s21_phase *= np.pi/180\n",
    "                    s_data.append( this_s21_amp*np.exp(1j*this_s21_phase) )\n",
    "\n",
    "                    # updating current row index\n",
    "                    current_row_i += num_rows\n",
    "\n",
    "    tup = tuple((tuple(x) for x in params))\n",
    "    count = Counter(tup)\n",
    "    for key,cnt in count.items():\n",
    "        if( cnt > 1 ):\n",
    "            positions = []\n",
    "            for i,param_combination in enumerate(params):\n",
    "                if( list(key) == param_combination ):\n",
    "                    positions.append(i)\n",
    "                    \n",
    "            print( \"non-unique parameter combination encountered: \", params[positions[0]])\n",
    "            print( \"duplicates are found in following files:\" )\n",
    "            for i in positions:\n",
    "                print( files_ret[i] )\n",
    "            \n",
    "    return files_ret, params, freqs, s_data\n",
    "\n",
    "def sort_by_params( param_indexes, params, list_to_sort ):\n",
    "    sorted_zip = sorted( zip( params, list_to_sort ), \\\n",
    "                        key=lambda x: tuple((float(x[0][param_idx]) for param_idx in param_indexes)) )\n",
    "    return [val for param,val in sorted_zip]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-78350c8cc647>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m### CUSTOMIZATION SECTION END ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_csv_from_dir\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_defaults\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m### CUSTOMIZATION SECTION START ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-1760db6f885b>\u001b[0m in \u001b[0;36mload_csv_from_dir\u001b[1;34m(dir_name, param_names, param_defaults)\u001b[0m\n\u001b[0;32m    151\u001b[0m                     \u001b[0mgroup_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_rows\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_row_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                         \u001b[1;31m# finding group of rows with specified parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "### CUSTOMIZATION SECTION START ###\n",
    "# setting parameter list (made by programmer for every new design)\n",
    "param_names = [\"Lcoupling\",\"toLine\",\"Z0b\"] \n",
    "param_defaults = {\"Lcoupling\":300,\"toLine\":50,\"Z0b\":30} # parameter values if they are not specified\n",
    "# all of the parameters should be specified\n",
    "# additional parameters are ignored\n",
    "### CUSTOMIZATION SECTION END ###\n",
    "\n",
    "files, params, freqs, s_data = load_csv_from_dir( dir_name, param_names, param_defaults )\n",
    "\n",
    "### CUSTOMIZATION SECTION START ###\n",
    "# sorting data\n",
    "s_data = sort_by_params( [2,1,0], params, s_data )\n",
    "freqs = sort_by_params( [2,1,0], params, freqs )\n",
    "files = sort_by_params( [2,1,0], params, files )\n",
    "params = sort_by_params( [2,1,0], params, params )\n",
    "### CUSTOMIZATION SECTION END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting data results with resonator_tools.notch_port\n",
    "fit_params = []\n",
    "for i,data in enumerate(s_data):\n",
    "    port1 = notch_port( freqs[i], data )\n",
    "    port1.autofit()\n",
    "    fit_params.append( port1.fitresults )\n",
    "\n",
    "# saving results into \".csv\" file\n",
    "with open( dir_name + \"../Results.csv\", \"w\" ) as csv_file:\n",
    "    writer = csv.writer( csv_file, delimiter=';', lineterminator='\\n')\n",
    "    writer.writerow( param_names + list(fit_params[0].keys()) )\n",
    "    for i,result in enumerate(fit_params):\n",
    "        writer.writerow( params[i] + list(result.values()) )\n",
    "\n",
    "# plottig custom results\n",
    "x_list = []\n",
    "indexes = []\n",
    "\n",
    "for i,param in enumerate(params):\n",
    "    if( float(param[1])==48 and float(param[2]) == 30 ):\n",
    "        x_list.append( float(param[0]) )\n",
    "        indexes.append(i)\n",
    "y_list = [fit_params[i][\"absQc\"] for i in indexes]\n",
    "\n",
    "# plot from param routine\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel(\"inverse length of capacitance, mkm\")\n",
    "plt.ylabel(\"coupling qualiti Q\")\n",
    "plt.plot( x_list, y_list, 'ro' )\n",
    "# visualizing parameter combination already obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
